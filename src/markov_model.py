import random
import pickle
import copy
from utility import Utility


class MarkovModel:

    def __init__(self):
        """
        __init__ constructor for the MarkovModel class

        Create a dictionary of (key,value) pairs where key is n-gram configuration
        """
        self.corpus = {}

    def read(self, filename, ngram=2):
        """
        read reads contents from a file

        It reads contents from a file,
        Splits contents into a list,
        Set up key as tuples of n word grams,
        Append word to the value in (key,value) dictionary pair, and
        Add new (key,value) pair if list does not exist.


        :param filename: name of the file to be opened
        :type filename: String
        :param ngram: number of ngrams specified, defaults to 2
        :type ngram: int, optional
        """

        # Read contents from a file
        content = Utility.read_contents_from_file(filename)

        # Split contents into a list
        content = content.split()
        total_words = len(content) - ngram

        for word in range(total_words):
            # Set up key as tuples of n word grams
            key = tuple(i for i in content[word:word + ngram])
            # Append word to the value in (key,value) dictionary pair
            # Add new (key,value) pair if list does not exist
            if key in self.corpus:
                self.corpus[key].append(content[word + ngram])
            else:
                self.corpus[key] = [content[word + ngram]]

    def _get_eot(self, list_of_texts):
        """
        _get_eot Obtain end of any given text based on position of last punctuation

        :param list_of_texts: list of text (sentence) including puncuations
        :type list_of_texts: list
        :return: index of where the suffix of text should be
        :rtype: int
        """
        eot_index = 0
        texts_size = len(list_of_texts) - 1

        for i in range(texts_size, 0, -1):
            # If puncuations, terminate here
            if list_of_texts[i][-1] in ['.', '!', '?']:
                eot_index = i+1
                break
            elif list_of_texts[i][-1] in [',', ';', ':']:
                eot_index = i
                break
        return eot_index

    def __get_text(self, n_length, words):
        """
        __get_text method to give text by appending words

        This methods generates an array of text using greedy model.

        :param n_length: length of sentence to be created
        :type n_length: int
        :param words: list of words to be fed into ngrams
        :type words: list
        :return: sentence generated by the function
        :rtype: str
        """
        resultant_text = []
        words_size = len(words) - 1

        # Contruct a text of size n words
        for ind in range(n_length):
            ngrams = tuple(words)

            # Capitalize solitary 'i'
            if words[0] == 'i':
                words[0].capitalize()

            resultant_text.append(words[0])

            # If words exist as key-words in corpus, shift by one word
            # Then select random word from the list of words that follow key-words
            if ngrams in self.corpus:
                words[:words_size] = words[1:words_size + 1]
                words[words_size] = random.choice(self.corpus[ngrams])

        resultant_text.append(words[words_size])

        # Capitalize first letter in resultant text
        resultant_text[0] = resultant_text[0].capitalize()

        # Obtain punctuation end
        end_of_text = self._get_eot(resultant_text)
        resultant_text = resultant_text[:end_of_text]

        return ' '.join(resultant_text)

    def __get_seedwords(self, seed_words, initials, w_c):
        """
        __get_seedwords  Make sure initial words are contained in seed words if they exist

        If initial words are in word-components and set seed words to be the word_components that contain initials

        :param seed_words: list of seed words to be included into the function
        :type seed_words: list
        :param initials: the list of suffix and prefix
        :type initials: list
        :param w_c: word component
        :type w_c: list
        :return: seed words according to the initials and word components
        :rtype: list
        """
        if type(initials) in [str]:
            initials = [initials]

        while initials and len(initials) > 0:
            for i in range(len(self.corpus)):
                # If initial words are in word-components
                # Set seed words to be the word_components that contain initials
                if initials[0] in w_c[i] or (tuple(initials[0].split()) == w_c[i]):
                    seed_words = list(w_c[i])
                    initials = []
                    break
            if len(initials) > 0:
                initials.pop(0)

        return list(seed_words)

    def generate_text(self, text_length, initials=['']):
        """
        generate_text Generates a text of sepecified length

        Convert corpus dictionary into a list of word-components,
        get random integer to obtain one 'word component' to start resultant sentence,
        obtain seedwords from initials if they exist in the corpus, and
        obtain resultant sentence of length n, commencing from seed words.

        :param text_length: length of the text to be generated
        :type text_length: int
        :param initials: list of initial words to start with, defaults to ['']
        :type initials: list, optional
        :return: resultant text generated by this module
        :rtype: str
        """
        if not self.corpus:
            print('Corpus Empty')

        # Convert corpus dictionary into a list of word-components
        word_components = list(self.corpus)
        random.shuffle(word_components)

        # Get random integer to obtain one 'word component' to start resultant sentence
        rand_int = random.randint(0, len(list(self.corpus)))
        seed_words = word_components[rand_int]

        # Obtain seedwords from initials if they exist in the corpus
        seed_words = self.__get_seedwords(
            seed_words, initials, word_components)

        # Obtain resultant sentence of length n, commencing from seed words
        error = True
        while error:
            resultant_text = self.__get_text(text_length, seed_words)
            if resultant_text != '':
                error = False

        return resultant_text

    def save(self, filename):
        """
        save Saves the corpus using pickle

        :param filename: filename for the corpus file to be saved
        :type filename: str
        """
        with open(filename, 'wb') as writer:
            pickle.dump(self.corpus, writer)

    def load(self, filename):
        """
        load Loads the saved pickle data

        Raise error if file does not exist and 
        Overwrites the corpus

        :param filename: filename of the saved corpus file
        :type filename: str
        """

        # Raise error if file does not exist
        if not Utility.check_integrity(filename):
            Utility.error('markov_model.load',
                          'File does not exist {0}'.format(filename))

        with open(filename, 'rb') as reader:
            data = pickle.load(reader)

        # Overwrite the corpus
        self.corpus = copy.deepcopy(data)

        del data
